{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mHTeUlReR84c",
        "outputId": "b4c40706-afe7-4020-eabd-1d53250f4c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "import tqdm\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
        "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "train_loader = DataLoader(training_data, shuffle = True, batch_size = 128)\n",
        "test_loader = DataLoader(test_data, shuffle = False, batch_size = 128)\n",
        "for i in train_loader:\n",
        "    print(i[0].shape, i[1].shape)\n",
        "    plt.imshow(i[0][0].squeeze(0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "class MSA101(nn.Module):\n",
        "    def __init__(self, d, n_heads=2):\n",
        "        super(MSA101, self).__init__()\n",
        "        self.d = d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
        "\n",
        "        d_head = int(d / n_heads)\n",
        "        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.d_head = d_head\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        # Sequences has shape (N, seq_length, token_dim)\n",
        "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
        "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
        "        result = []\n",
        "        for sequence in sequences:\n",
        "            seq_result = []\n",
        "            for head in range(self.n_heads):\n",
        "                q_mapping = self.q_mappings[head]\n",
        "                k_mapping = self.k_mappings[head]\n",
        "                v_mapping = self.v_mappings[head]\n",
        "\n",
        "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
        "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
        "\n",
        "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
        "                seq_result.append(attention @ v)\n",
        "            result.append(torch.hstack(seq_result))\n",
        "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n",
        "\n",
        "class ViTBlock(nn.Module):\n",
        "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
        "        super(ViTBlock, self).__init__()\n",
        "        self.hidden_d = hidden_d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_d)\n",
        "        self.mhsa = MSA101(hidden_d, n_heads)\n",
        "        self.norm2 = nn.LayerNorm(hidden_d)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.mhsa(self.norm1(x))\n",
        "        out = out + self.mlp(self.norm2(out))\n",
        "        return out\n",
        "\n",
        "class ViT101(nn.Module):\n",
        "    def __init__(self, chw = (1,28,28), patch_size = 4, hidden_d = 8, n_blocks=2, n_heads=2, out_d=10):\n",
        "        super(ViT101, self).__init__()\n",
        "        self.chw = chw\n",
        "        self.hidden_d = hidden_d\n",
        "        self.patch_size = patch_size\n",
        "        self.input_d = chw[0] * patch_size * patch_size\n",
        "    \n",
        "        assert chw[1]==chw[2], 'please square img'\n",
        "        assert chw[1] % patch_size == 0 and chw[2] % patch_size == 0, 'h and w should be divisible by patch_size'\n",
        "\n",
        "        num_patches = (self.chw[1] // self.patch_size) * (self.chw[2] // self.patch_size)\n",
        "        # patchify\n",
        "        self.to_patch = nn.Sequential(Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size))    \n",
        "        # linear mapping\n",
        "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
        "        # classification tokens\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.hidden_d))\n",
        "        # position embeddings\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, self.hidden_d))\n",
        "        # create meat\n",
        "        self.blocks = nn.ModuleList([ViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
        "        # classificate\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(self.hidden_d, out_d),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch(x)\n",
        "        b, n, _ = x.shape\n",
        "        x = self.linear_mapper(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        for block in self.blocks:\n",
        "            out = block(x)\n",
        "        # Getting the classification token only\n",
        "        out = out[:, 0]\n",
        "        \n",
        "        return self.mlp(out) "
      ],
      "metadata": {
        "id": "HD-gqhK2dh5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a129ad06-98ae-4480-f5a8-ff7c24aed77f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT101()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "epochs = 5\n",
        "for epoch in range(1,epochs+1):\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for (images, labels) in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        p_labels = model(images)\n",
        "        loss = criterion(p_labels, labels)\n",
        "        train_loss += loss.detach().cpu().item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print (f'epoch: {epoch} train loss: {train_loss/len(train_loader)}')\n",
        "\n",
        "    test_loss = 0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            p_labels = model(images)\n",
        "            loss = criterion(p_labels, labels)\n",
        "            test_loss += loss.detach().cpu().item()\n",
        "            pred = p_labels.argmax(dim=1, keepdim=True) \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    print (f'epoch: {epoch} test loss: {test_loss/len(test_loader)} accuracy: {correct/len(test_loader)}')"
      ],
      "metadata": {
        "id": "jY2IUALTTaGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbe2dda-f244-4db6-ab41-ce80fe7b6ec6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 train loss: 2.1768749299079877\n",
            "epoch: 1 test loss: 2.036287153823466 accuracy: 54.43037974683544\n",
            "epoch: 2 train loss: 1.9646807049891588\n",
            "epoch: 2 test loss: 1.8766154790226417 accuracy: 75.78481012658227\n",
            "epoch: 3 train loss: 1.8468450229051017\n",
            "epoch: 3 test loss: 1.8013120587868026 accuracy: 83.9873417721519\n",
            "epoch: 4 train loss: 1.8045040973976476\n",
            "epoch: 4 test loss: 1.7768752152406717 accuracy: 87.0379746835443\n",
            "epoch: 5 train loss: 1.781542129862283\n",
            "epoch: 5 test loss: 1.7602002560337888 accuracy: 89.0253164556962\n"
          ]
        }
      ]
    }
  ]
}